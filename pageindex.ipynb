{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f463e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1e4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pageindex import PageIndexClient\n",
    "import pageindex.utils as utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a310515",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pi_client = PageIndexClient(api_key=os.getenv(\"PAGEINDEX_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b4d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "async def call_llm(prompt, model=\"stepfun/step-3.5-flash:free\", temperature=0):\n",
    "    client = openai.AsyncOpenAI(api_key=os.getenv(\"OPENROUTER_API_KEY\"))\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145af758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://arxiv.org/pdf/2506.08276.pdf\n",
      "Document Submitted: pi-cmm2gj5it028p0ko9q2fyi5np\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# You can also use our GitHub repo to generate PageIndex tree\n",
    "# https://github.com/VectifyAI/PageIndex\n",
    "\n",
    "pdf_url = \"https://arxiv.org/pdf/2506.08276.pdf\"\n",
    "pdf_path = os.path.join(\"../data\", pdf_url.split('/')[-1])\n",
    "os.makedirs(os.path.dirname(pdf_path), exist_ok=True)\n",
    "\n",
    "response = requests.get(pdf_url)\n",
    "with open(pdf_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(f\"Downloaded {pdf_url}\")\n",
    "\n",
    "doc_id = _pi_client.submit_document(pdf_path)[\"doc_id\"]\n",
    "print('Document Submitted:', doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e12898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified Tree Structure of the Document:\n",
      "[{'title': 'ABSTRACT', 'node_id': '0000', 'summary': 'The text introduces LEANN, a storage-eff...'},\n",
      " {'title': '1 INTRODUCTION',\n",
      "  'node_id': '0001',\n",
      "  'summary': 'The text introduces vector search as a c...'},\n",
      " {'title': '3 LEANN Overview',\n",
      "  'node_id': '0002',\n",
      "  'summary': 'The text describes the LEANN system, whi...'},\n",
      " {'title': '4 GRAPH-BASED RECOMPUTATION',\n",
      "  'node_id': '0003',\n",
      "  'summary': '# 4 GRAPH-BASED RECOMPUTATION\\n\\nIn this s...'},\n",
      " {'title': '5 COMPACT GRAPH STRUCTURE',\n",
      "  'node_id': '0004',\n",
      "  'summary': \"This text describes LEANN's approach to ...\"},\n",
      " {'title': '6 Index Building and Update',\n",
      "  'node_id': '0005',\n",
      "  'summary': \"The text describes LEANN's approach to b...\"},\n",
      " {'title': '7 EVALUATION',\n",
      "  'node_id': '0006',\n",
      "  'prefix_summary': '# 7 EVALUATION\\n\\nWe begin by describing t...',\n",
      "  'nodes': [{'title': '7.1 Experiment Settings',\n",
      "             'node_id': '0007',\n",
      "             'summary': 'The text details the experiment settings...'},\n",
      "            {'title': '7.2 Main results',\n",
      "             'node_id': '0008',\n",
      "             'summary': 'The text presents a comprehensive evalua...'},\n",
      "            {'title': '7.3 Ablation Studies and Micro Benchmark...',\n",
      "             'node_id': '0009',\n",
      "             'summary': 'This section presents ablation studies a...'}]},\n",
      " {'title': '8 RELATED WORK',\n",
      "  'node_id': '0010',\n",
      "  'summary': 'This section reviews related work in res...'},\n",
      " {'title': '9 Conclusions',\n",
      "  'node_id': '0011',\n",
      "  'summary': '# 9 Conclusions\\n\\nSimilarity search over ...'},\n",
      " {'title': 'References',\n",
      "  'node_id': '0012',\n",
      "  'summary': 'This text is a comprehensive list of ref...'},\n",
      " {'title': 'A RNG PRUNING',\n",
      "  'node_id': '0013',\n",
      "  'summary': 'The text describes the Random Geometric ...'},\n",
      " {'title': 'B LEANN UPDATE STRATEGY',\n",
      "  'node_id': '0014',\n",
      "  'prefix_summary': '# B LEANN UPDATE STRATEGY\\n\\nThe ADD algor...',\n",
      "  'nodes': [{'title': 'B.1 Add Operation: Method and Time Compl...',\n",
      "             'node_id': '0015',\n",
      "             'summary': 'The text details the time complexity of ...'},\n",
      "            {'title': 'B.2 Batched Add Operation: Optimization',\n",
      "             'node_id': '0016',\n",
      "             'summary': '## B.2 Batched Add Operation: Optimizati...'},\n",
      "            {'title': 'B.3 Soft Deletion Strategy',\n",
      "             'node_id': '0017',\n",
      "             'summary': \"The text details LEANN's soft deletion s...\"},\n",
      "            {'title': 'Appendix C Evaluation details',\n",
      "             'node_id': '0018',\n",
      "             'summary': '## Appendix C Evaluation details\\n'},\n",
      "            {'title': 'C.1 Baseline Configurations',\n",
      "             'node_id': '0019',\n",
      "             'summary': 'The text describes baseline configuratio...'},\n",
      "            {'title': 'C.2 Latency Measurement and Evaluation P...',\n",
      "             'node_id': '0020',\n",
      "             'summary': 'The text describes a protocol for evalua...'},\n",
      "            {'title': 'C.3 Latency Measurement in RAG Pipeline',\n",
      "             'node_id': '0021',\n",
      "             'summary': '## C.3 Latency Measurement in RAG Pipeli...'},\n",
      "            {'title': 'C.4 RAG Latency on Mac Platform',\n",
      "             'node_id': '0022',\n",
      "             'summary': '## C.4 RAG Latency on Mac Platform\\n\\nTo v...'},\n",
      "            {'title': 'Appendix D More Ablation Studies',\n",
      "             'node_id': '0023',\n",
      "             'summary': '## Appendix D More Ablation Studies\\n'},\n",
      "            {'title': 'D.1 Comparison of Index Construction',\n",
      "             'node_id': '0024',\n",
      "             'summary': 'This text compares storage-efficient ind...'},\n",
      "            {'title': 'D.2 Using Different Embedding Model Size...',\n",
      "             'node_id': '0025',\n",
      "             'summary': 'This section explores reducing system la...'},\n",
      "            {'title': 'D.3 Relaxing Disk Constraint',\n",
      "             'node_id': '0026',\n",
      "             'summary': 'This text discusses the benefits of rela...'},\n",
      "            {'title': 'D.4 Graph-based Recomputation Breakdown',\n",
      "             'node_id': '0027',\n",
      "             'summary': '## D.4 Graph-based Recomputation Breakdo...'}]}]\n"
     ]
    }
   ],
   "source": [
    "if _pi_client.is_retrieval_ready(doc_id):\n",
    "    tree = _pi_client.get_tree(doc_id, node_summary=True)['result']\n",
    "    print('Simplified Tree Structure of the Document:')\n",
    "    utils.print_tree(tree)\n",
    "else:\n",
    "    print(\"Processing document, please try again later...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a99fd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-or-v1*************************************************************e8a6. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m      5\u001b[39m tree_without_text = utils.remove_fields(tree.copy(), fields=[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      7\u001b[39m search_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33mYou are given a question and a tree structure of a document.\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33mEach node contains a node id, node title, and a corresponding summary.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \u001b[33mDirectly return the final JSON structure. Do not output anything else.\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m tree_search_result = \u001b[38;5;28;01mawait\u001b[39;00m call_llm(search_prompt)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcall_llm\u001b[39m\u001b[34m(prompt, model, temperature)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_llm\u001b[39m(prompt, model=\u001b[33m\"\u001b[39m\u001b[33mstepfun/step-3.5-flash:free\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0\u001b[39m):\n\u001b[32m      4\u001b[39m     client = openai.AsyncOpenAI(api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENROUTER_API_KEY\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m client.chat.completions.create(\n\u001b[32m      6\u001b[39m         model=model,\n\u001b[32m      7\u001b[39m         messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: prompt}],\n\u001b[32m      8\u001b[39m         temperature=temperature\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\pageindex-exp\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2700\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2653\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   2654\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   2655\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2697\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   2698\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   2699\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2700\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2701\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2702\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2703\u001b[39m             {\n\u001b[32m   2704\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2705\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2706\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2707\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2708\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2709\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2710\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2711\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2712\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2713\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2714\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2715\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2716\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2717\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2718\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2719\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2720\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2721\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_retention\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_retention,\n\u001b[32m   2722\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2723\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2724\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2725\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2726\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2727\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2728\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2729\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2730\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2731\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2732\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2735\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2736\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2737\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2738\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2739\u001b[39m             },\n\u001b[32m   2740\u001b[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2741\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2742\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2743\u001b[39m         ),\n\u001b[32m   2744\u001b[39m         options=make_request_options(\n\u001b[32m   2745\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2746\u001b[39m         ),\n\u001b[32m   2747\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2748\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2749\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2750\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\pageindex-exp\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1884\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, content, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1875\u001b[39m     warnings.warn(\n\u001b[32m   1876\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing raw bytes as `body` is deprecated and will be removed in a future version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1877\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease pass raw bytes via the `content` parameter instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1878\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   1879\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1880\u001b[39m     )\n\u001b[32m   1881\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1882\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, content=content, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1883\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1884\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\pageindex-exp\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1669\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1666\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1668\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1669\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1671\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1673\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-or-v1*************************************************************e8a6. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "query = \"What are the conclusions in this document?\"\n",
    "\n",
    "tree_without_text = utils.remove_fields(tree.copy(), fields=['text'])\n",
    "\n",
    "search_prompt = f\"\"\"\n",
    "You are given a question and a tree structure of a document.\n",
    "Each node contains a node id, node title, and a corresponding summary.\n",
    "Your task is to find all nodes that are likely to contain the answer to the question.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Document tree structure:\n",
    "{json.dumps(tree_without_text, indent=2)}\n",
    "\n",
    "Please reply in the following JSON format:\n",
    "{{\n",
    "    \"thinking\": \"<Your thinking process on which nodes are relevant to the question>\",\n",
    "    \"node_list\": [\"node_id_1\", \"node_id_2\", ..., \"node_id_n\"]\n",
    "}}\n",
    "Directly return the final JSON structure. Do not output anything else.\n",
    "\"\"\"\n",
    "\n",
    "tree_search_result = await call_llm(search_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f148757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943e308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0de58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
